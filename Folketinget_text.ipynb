{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OData API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://oda.ft.dk/Home/OdataQuery\n",
    "\n",
    "https://www.odata.org/\n",
    "\n",
    "https://www.ft.dk/-/media/sites/ft/pdf/dokumenter/aabne-data/oda-browser_brugervejledning.ashx\n",
    "\n",
    "https://www.odata.org/documentation/odata-version-3-0/url-conventions/\n",
    "\n",
    "https://www.odata.org/documentation/odata-version-3-0/odata-version-3-0-core-protocol/\n",
    "\n",
    "Source root Link: \"https://oda.ft.dk/api/\"\n",
    "\n",
    "ftp://oda.ft.dk/ODAXML/Referat/samling/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folketinget data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data related to the meetings in Folketinget is collected following the guide on Folketinget's homepage:\n",
    "https://www.ft.dk/-/media/sites/ft/pdf/dokumenter/aabne-data/oda-browser_brugervejledning.ashx.\n",
    "Transcripts from all meetings going back to 2009 are available for download in xml format using a login described in the guide and some specific ftp software. Because it is interesting to compare topics from Twitter with topics in Folketinget, only the transcripts from the same period as the tweets are used for further analysis. 71% of the available tweets are posted in 2018 and after.\n",
    "\n",
    "The years in Folketinget do not follow the calender year, as they start and end the first Tuesday of October. So, the meetings from 2018 are actually from October 2017 to October 2018. The data from 2017 are kept for the purpose of having slightly more data and because it is assumed that topics vary little enought for it to still be relevant.\n",
    "\n",
    "In total 284 meeting stranscripts amounting to 256.6Mb of data has been downloaded and parsed for analysis.\n",
    "\n",
    "It is not stated how the transcripts are made, however, they are proofread before publication. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install bs4 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from bs4.element import Comment\n",
    "import lxml\n",
    "\n",
    "import xml.etree.ElementTree as et \n",
    "from xml.dom import minidom\n",
    "\n",
    "import re\n",
    "\n",
    "import dateutil\n",
    "import datetime as dt\n",
    "from dateutil.easter import *\n",
    "from dateutil.rrule import *\n",
    "from dateutil.parser import *\n",
    "from datetime import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = path+'/samling/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/frederikkromannhansen/Documents/GitHub/politiker/samling/'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20181_M10_helemoedet.xml       20181_M52_helemoedet.xml\r\n",
      "20181_M11_helemoedet.xml       20181_M53_helemoedet.xml\r\n",
      "20181_M12_helemoedet.xml       20181_M54_helemoedet.xml\r\n",
      "20181_M13_helemoedet.xml       20181_M55_helemoedet.xml\r\n",
      "20181_M14_helemoedet.xml       20181_M56_helemoedet.xml\r\n",
      "20181_M15_helemoedet.xml       20181_M57_helemoedet.xml\r\n",
      "20181_M16_helemoedet.xml       20181_M58_helemoedet.xml\r\n",
      "20181_M17_helemoedet.xml       20181_M59_helemoedet.xml\r\n",
      "20181_M18_helemoedet.xml       20181_M5_helemoedet.xml\r\n",
      "20181_M19_helemoedet.xml       20181_M60_helemoedet.xml\r\n",
      "20181_M1_helemoedet.xml        20181_M61_helemoedet.xml\r\n",
      "20181_M1_helemoedet_clean.xml  20181_M62_helemoedet.xml\r\n",
      "20181_M20_helemoedet.xml       20181_M63_helemoedet.xml\r\n",
      "20181_M21_helemoedet.xml       20181_M64_helemoedet.xml\r\n",
      "20181_M22_helemoedet.xml       20181_M65_helemoedet.xml\r\n",
      "20181_M23_helemoedet.xml       20181_M66_helemoedet.xml\r\n",
      "20181_M24_helemoedet.xml       20181_M67_helemoedet.xml\r\n",
      "20181_M25_helemoedet.xml       20181_M68_helemoedet.xml\r",
      "\r\n",
      "20181_M26_helemoedet.xml       20181_M69_helemoedet.xml\r\n",
      "20181_M27_helemoedet.xml       20181_M6_helemoedet.xml\r\n",
      "20181_M28_helemoedet.xml       20181_M70_helemoedet.xml\r\n",
      "20181_M29_helemoedet.xml       20181_M71_helemoedet.xml\r\n",
      "20181_M2_helemoedet.xml        20181_M72_helemoedet.xml\r\n",
      "20181_M30_helemoedet.xml       20181_M73_helemoedet.xml\r\n",
      "20181_M31_helemoedet.xml       20181_M74_helemoedet.xml\r\n",
      "20181_M32_helemoedet.xml       20181_M75_helemoedet.xml\r\n",
      "20181_M33_helemoedet.xml       20181_M76_helemoedet.xml\r\n",
      "20181_M34_helemoedet.xml       20181_M77_helemoedet.xml\r\n",
      "20181_M35_helemoedet.xml       20181_M78_helemoedet.xml\r\n",
      "20181_M36_helemoedet.xml       20181_M79_helemoedet.xml\r\n",
      "20181_M37_helemoedet.xml       20181_M7_helemoedet.xml\r\n",
      "20181_M38_helemoedet.xml       20181_M80_helemoedet.xml\r\n",
      "20181_M39_helemoedet.xml       20181_M81_helemoedet.xml\r\n",
      "20181_M3_helemoedet.xml        20181_M82_helemoedet.xml\r\n",
      "20181_M40_helemoedet.xml       20181_M83_helemoedet.xml\r\n",
      "20181_M41_helemoedet.xml       20181_M84_helemoedet.xml\r\n",
      "20181_M42_helemoedet.xml       20181_M85_helemoedet.xml\r\n",
      "20181_M43_helemoedet.xml       20181_M86_helemoedet.xml\r\n",
      "20181_M44_helemoedet.xml       20181_M87_helemoedet.xml\r\n",
      "20181_M45_helemoedet.xml       20181_M88_helemoedet.xml\r\n",
      "20181_M46_helemoedet.xml       20181_M89_helemoedet.xml\r\n",
      "20181_M47_helemoedet.xml       20181_M8_helemoedet.xml\r\n",
      "20181_M48_helemoedet.xml       20181_M90_helemoedet.xml\r\n",
      "20181_M49_helemoedet.xml       20181_M91_helemoedet.xml\r\n",
      "20181_M4_helemoedet.xml        20181_M92_helemoedet.xml\r\n",
      "20181_M50_helemoedet.xml       20181_M93_helemoedet.xml\r\n",
      "20181_M51_helemoedet.xml       20181_M9_helemoedet.xml\r\n"
     ]
    }
   ],
   "source": [
    "ls samling/20181"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Dokument': 1,\n",
       "         'MetaMeeting': 1,\n",
       "         'ParliamentarySession': 1,\n",
       "         'ParliamentaryGroup': 1,\n",
       "         'MeetingNumber': 1,\n",
       "         'DateOfSitting': 1,\n",
       "         'Location': 1,\n",
       "         'EdixiDocLocation': 1,\n",
       "         'AudioFileFolder': 1,\n",
       "         'TitelGruppe': 1,\n",
       "         'Titel': 1,\n",
       "         'Linea': 126,\n",
       "         'Char': 138,\n",
       "         'UnderTitel': 1,\n",
       "         'DagsordenPlan': 1,\n",
       "         'Rubrica': 10,\n",
       "         'PunktTekst': 8,\n",
       "         'Exitus': 72,\n",
       "         'DagsordenPunkt': 5,\n",
       "         'MetaFTAgendaItem': 5,\n",
       "         'ItemNo': 5,\n",
       "         'FTCase': 5,\n",
       "         'FTCaseNumber': 5,\n",
       "         'FTCaseType': 5,\n",
       "         'FTCaseStage': 5,\n",
       "         'ShortTitle': 5,\n",
       "         'Aktivitet': 10,\n",
       "         'Tale': 12,\n",
       "         'Taler': 12,\n",
       "         'MetaSpeakerMP': 12,\n",
       "         'OratorFirstName': 12,\n",
       "         'OratorLastName': 12,\n",
       "         'GroupNameShort': 12,\n",
       "         'OratorRole': 12,\n",
       "         'TalerTitel': 12,\n",
       "         'TaleSegment': 12,\n",
       "         'MetaSpeechSegment': 12,\n",
       "         'LastModified': 12,\n",
       "         'EdixiStatus': 12,\n",
       "         'StartDateTime': 12,\n",
       "         'EndDateTime': 11,\n",
       "         'TekstGruppe': 26,\n",
       "         'PreTekst': 3,\n",
       "         'TaleType': 1})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for subdir, dir, files in os.walk(path):\n",
    "    for file in files:\n",
    "        filepath = subdir+'/' + file\n",
    "        if filepath.endswith(\".xml\"):\n",
    "            xmlTree = et.parse(filepath)\n",
    "            \n",
    "elemList = []\n",
    "\n",
    "for elem in xmlTree.iter():\n",
    "    elemList.append(elem.tag)\n",
    "\n",
    "# now I remove duplicities - by convertion to set and back to list\n",
    "#elemList = list(set(elemList))\n",
    "\n",
    "# Just printing out the result\n",
    "from collections import Counter\n",
    "Counter(elemList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for speech in root.iter('Tale'):\n",
    "    tags=[node.tag for node in speech.iter()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tale',\n",
       " 'Taler',\n",
       " 'MetaSpeakerMP',\n",
       " 'OratorFirstName',\n",
       " 'OratorLastName',\n",
       " 'GroupNameShort',\n",
       " 'OratorRole',\n",
       " 'TalerTitel',\n",
       " 'Linea',\n",
       " 'Char',\n",
       " 'Char',\n",
       " 'TaleSegment',\n",
       " 'MetaSpeechSegment',\n",
       " 'LastModified',\n",
       " 'EdixiStatus',\n",
       " 'StartDateTime',\n",
       " 'TekstGruppe',\n",
       " 'Exitus',\n",
       " 'Linea',\n",
       " 'Char',\n",
       " 'Linea',\n",
       " 'Char',\n",
       " 'Linea',\n",
       " 'Char']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "starttid_vec = []\n",
    "sluttid_vec=[]\n",
    "navn_vec = []\n",
    "efternavn_vec = []\n",
    "tekst_vec = []\n",
    "parti_vec = []\n",
    "rolle_vec = []\n",
    "meetingID_vec = []\n",
    "itemNo_vec = []\n",
    "\n",
    "# Go through all the folders and files containing transcripts\n",
    "for subdir, dir, files in os.walk(path):\n",
    "    for file in files:\n",
    "        filepath = subdir+'/' + file\n",
    "        if filepath.endswith(\".xml\"):\n",
    "            tree = et.parse(filepath)\n",
    "            root = tree.getroot() \n",
    "            \n",
    "            for meeting in root.iter('MeetingNumber'):\n",
    "                meetingID = meeting.text\n",
    "\n",
    "                for ItemNo in root.iter('ItemNo'):\n",
    "                    \n",
    "                # Do this if the speaker has an associated party, i.e. not a minister or the chairman\n",
    "                    for speech in root.iter('Tale'):\n",
    "\n",
    "                        tags=[node.tag for node in speech.iter()]\n",
    "                        if('TekstGruppe' in tags):\n",
    "                            if('GroupNameShort' in tags):\n",
    "                                for node in speech.iter():\n",
    "                                    if(node.tag == 'StartDateTime'):\n",
    "                                        starttid_vec.append(node.text)\n",
    "                                    elif(node.tag == 'OratorFirstName'):\n",
    "                                        navn_vec.append(node.text)\n",
    "                                    elif(node.tag == 'OratorLastName'):\n",
    "                                        efternavn_vec.append(node.text)\n",
    "                                        #print('Meeting ID: ', meetingID, 'Item No: ', ItemNo.text, 'Speaker: ', node.text)\n",
    "                                    elif(node.tag == 'OratorRole'):\n",
    "                                        rolle_vec.append(node.text)\n",
    "                                    elif(node.tag=='TekstGruppe'):\n",
    "                                        # This tag is preculiar, as there are multiple children ending with 'Char' as the youngest.\n",
    "                                        # Concate all text within 'TekstGruppe'.\n",
    "                                        tekstgruppe = ''\n",
    "                                        for k in node.iter():\n",
    "                                            if k.tag==\"Char\":\n",
    "                                                tekstgruppe+=' '+k.text\n",
    "                                        tekst_vec.append(tekstgruppe)\n",
    "                                    elif(node.tag=='GroupNameShort'):\n",
    "                                        parti_vec.append(node.text)\n",
    "\n",
    "                                        meetingID_vec.append(meetingID)\n",
    "                                        itemNo_vec.append(ItemNo.text)\n",
    "\n",
    "\n",
    "                                    # If there are more text than speaker names, remove the excess.\n",
    "                                    # We will loose a few pieces of text but only around 1%\n",
    "                                    if len(tekst_vec)>len(navn_vec):\n",
    "                                        tekst_vec.pop()\n",
    "                                    if len(starttid_vec)>len(navn_vec):\n",
    "                                        starttid_vec.pop()\n",
    "\n",
    "                            # Do this if the speaker is either a minister or the chairman\n",
    "                            else:\n",
    "                                parti_vec.append('Ukendt')\n",
    "                                for node in speech.iter():\n",
    "                                    if(node.tag == 'StartDateTime'):\n",
    "                                        starttid_vec.append(node.text)\n",
    "                                    elif(node.tag == 'OratorFirstName'):\n",
    "                                        navn_vec.append(node.text)\n",
    "                                    elif(node.tag == 'OratorLastName'):\n",
    "                                        efternavn_vec.append(node.text)\n",
    "                                    elif(node.tag == 'OratorRole'):\n",
    "                                        rolle_vec.append(node.text)\n",
    "                                    elif(node.tag=='TekstGruppe'):\n",
    "                                        # This tag is preculiar, as there are multiple children ending with 'Char' as the youngest.\n",
    "                                        # Concate all text within 'TekstGruppe'.\n",
    "                                        tekstgruppe = ''\n",
    "                                        for k in node.iter():\n",
    "                                            if k.tag==\"Char\":\n",
    "                                                tekstgruppe+=' '+k.text\n",
    "                                        tekst_vec.append(tekstgruppe)\n",
    "\n",
    "                                        meetingID_vec.append(meetingID)\n",
    "                                        itemNo_vec.append(ItemNo.text)\n",
    "\n",
    "                                    # If there are more text than speaker names, remove the excess.\n",
    "                                    # We will loose a few pieces of text but only around 1%\n",
    "                                    if len(tekst_vec)>len(navn_vec):\n",
    "                                        tekst_vec.pop()\n",
    "                                    if len(starttid_vec)>len(navn_vec):\n",
    "                                        starttid_vec.pop()\n",
    "                    \n",
    "\n",
    "\n",
    "# Add everuthing to a dictionary and transform it into a Pandas dataframe\n",
    "dictionary= {'MeetingID':meetingID_vec, 'ItemNo':itemNo_vec, 'StartDateTime':starttid_vec,'OratorFirstName':navn_vec,'OratorLastName':efternavn_vec,\n",
    "                 'GroupNameShort':parti_vec,'OratorRole':rolle_vec ,'TekstGruppe':tekst_vec} # 'EndDateTime':sluttid_vec,\n",
    "df = pd.DataFrame(dictionary)\n",
    "\n",
    "print('In total, there are {} lines of text in the meetings.'.format(len(df)))\n",
    "#df.to_csv(path[0:26]+'csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MeetingID</th>\n",
       "      <th>ItemNo</th>\n",
       "      <th>StartDateTime</th>\n",
       "      <th>OratorFirstName</th>\n",
       "      <th>OratorLastName</th>\n",
       "      <th>GroupNameShort</th>\n",
       "      <th>OratorRole</th>\n",
       "      <th>TekstGruppe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-27T13:00:08</td>\n",
       "      <td>Pia</td>\n",
       "      <td>Kjærsgaard</td>\n",
       "      <td>DF</td>\n",
       "      <td>formand</td>\n",
       "      <td>Mødet er åbnet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-27T13:01:34</td>\n",
       "      <td>Pia</td>\n",
       "      <td>Kjærsgaard</td>\n",
       "      <td>DF</td>\n",
       "      <td>formand</td>\n",
       "      <td>Det første spørgsmål er til justitsministeren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-27T13:01:43</td>\n",
       "      <td>Pia</td>\n",
       "      <td>Kjærsgaard</td>\n",
       "      <td>DF</td>\n",
       "      <td>formand</td>\n",
       "      <td>Værsgo for at oplæse spørgsmålet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-27T13:01:45</td>\n",
       "      <td>Christian</td>\n",
       "      <td>Langballe</td>\n",
       "      <td>DF</td>\n",
       "      <td>medlem</td>\n",
       "      <td>Spørgsmålet lyder: Vil regeringen stå fast på...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-27T13:02:05</td>\n",
       "      <td>Pia</td>\n",
       "      <td>Kjærsgaard</td>\n",
       "      <td>DF</td>\n",
       "      <td>formand</td>\n",
       "      <td>Værsgo, ministeren.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  MeetingID ItemNo        StartDateTime OratorFirstName OratorLastName  \\\n",
       "0        66      0  2019-02-27T13:00:08             Pia     Kjærsgaard   \n",
       "1        66      0  2019-02-27T13:01:34             Pia     Kjærsgaard   \n",
       "2        66      0  2019-02-27T13:01:43             Pia     Kjærsgaard   \n",
       "3        66      0  2019-02-27T13:01:45       Christian      Langballe   \n",
       "4        66      0  2019-02-27T13:02:05             Pia     Kjærsgaard   \n",
       "\n",
       "  GroupNameShort OratorRole                                        TekstGruppe  \n",
       "0             DF    formand                                    Mødet er åbnet.  \n",
       "1             DF    formand   Det første spørgsmål er til justitsministeren...  \n",
       "2             DF    formand                  Værsgo for at oplæse spørgsmålet.  \n",
       "3             DF     medlem   Spørgsmålet lyder: Vil regeringen stå fast på...  \n",
       "4             DF    formand                                Værsgo, ministeren.  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Til formand har Socialdemokratiet, Dansk Folkeparti, Venstre, Liberal Alliance, Det Konservative Folkeparti, Nunatta Qitornai, Tjóðveldi og Javnaðarflokkurin indstillet fru Pia Kjærsgaard. Der foreligger ikke andre indstillinger.\n"
     ]
    }
   ],
   "source": [
    "print(df.TekstGruppe[74023])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, there are 110438 lines of text in the meetings.\n"
     ]
    }
   ],
   "source": [
    "starttid_vec = []\n",
    "sluttid_vec=[]\n",
    "navn_vec = []\n",
    "efternavn_vec = []\n",
    "tekst_vec = []\n",
    "parti_vec = []\n",
    "rolle_vec = []\n",
    "meetingID_vec = []\n",
    "\n",
    "\n",
    "# Go through all the folders and files containing transcripts\n",
    "for subdir, dir, files in os.walk(path):\n",
    "    for file in files:\n",
    "        filepath = subdir+'/' + file\n",
    "        if (filepath.endswith(\".xml\")) and not (filepath.endswith(\"clean.xml\")):\n",
    "            tree = et.parse(filepath)\n",
    "            root = tree.getroot() \n",
    "\n",
    "            for meeting in root.iter('MeetingNumber'):\n",
    "                meetingID = meeting.text\n",
    "            # Do this if the speaker has an associated party, i.e. not a minister or the chairman\n",
    "            for speech in root.iter('Tale'):\n",
    "\n",
    "                tags=[node.tag for node in speech.iter()]\n",
    "                if('TekstGruppe' in tags):\n",
    "                    if('GroupNameShort' in tags):\n",
    "                        for node in speech.iter():\n",
    "                            if(node.tag == 'StartDateTime'):\n",
    "                                starttid_vec.append(node.text)\n",
    "                            elif(node.tag == 'OratorFirstName'):\n",
    "                                navn_vec.append(node.text)\n",
    "                            elif(node.tag == 'OratorLastName'):\n",
    "                                efternavn_vec.append(node.text)\n",
    "                            elif(node.tag == 'OratorRole'):\n",
    "                                rolle_vec.append(node.text)\n",
    "                            elif(node.tag=='TekstGruppe'):\n",
    "                                # This tag is preculiar, as there are multiple children ending with 'Char' as the youngest.\n",
    "                                # Concate all text within 'TekstGruppe'.\n",
    "                                tekstgruppe = ''\n",
    "                                for k in node.iter():\n",
    "                                    if k.tag==\"Char\":\n",
    "                                        tekstgruppe+=' '+k.text\n",
    "                                tekst_vec.append(tekstgruppe)\n",
    "                            elif(node.tag=='GroupNameShort'):\n",
    "                                parti_vec.append(node.text)\n",
    "                                \n",
    "                                meetingID_vec.append(meetingID)\n",
    "\n",
    "\n",
    "                            # If there are more text than speaker names, remove the excess.\n",
    "                            # We will loose a few pieces of text but only around 1%\n",
    "                            if len(tekst_vec)>len(navn_vec):\n",
    "                                tekst_vec.pop()\n",
    "                            if len(starttid_vec)>len(navn_vec):\n",
    "                                starttid_vec.pop()\n",
    "\n",
    "                    # Do this if the speaker is either a minister or the chairman\n",
    "                    else:\n",
    "                        parti_vec.append('Ukendt')\n",
    "                        for node in speech.iter():\n",
    "                            if(node.tag == 'StartDateTime'):\n",
    "                                starttid_vec.append(node.text)\n",
    "                            elif(node.tag == 'OratorFirstName'):\n",
    "                                navn_vec.append(node.text)\n",
    "                            elif(node.tag == 'OratorLastName'):\n",
    "                                efternavn_vec.append(node.text)\n",
    "                            elif(node.tag == 'OratorRole'):\n",
    "                                rolle_vec.append(node.text)\n",
    "                            elif(node.tag=='TekstGruppe'):\n",
    "                                # This tag is preculiar, as there are multiple children ending with 'Char' as the youngest.\n",
    "                                # Concate all text within 'TekstGruppe'.\n",
    "                                tekstgruppe = ''\n",
    "                                for k in node.iter():\n",
    "                                    if k.tag==\"Char\":\n",
    "                                        tekstgruppe+=' '+k.text\n",
    "                                tekst_vec.append(tekstgruppe)\n",
    "                                \n",
    "                                meetingID_vec.append(meetingID)\n",
    "\n",
    "                            # If there are more text than speaker names, remove the excess.\n",
    "                            # We will loose a few pieces of text but only around 1%\n",
    "                            if len(tekst_vec)>len(navn_vec):\n",
    "                                tekst_vec.pop()\n",
    "                            if len(starttid_vec)>len(navn_vec):\n",
    "                                starttid_vec.pop()\n",
    "                    \n",
    "\n",
    "\n",
    "# Add everuthing to a dictionary and transform it into a Pandas dataframe\n",
    "dictionary= {'MeetingID':meetingID_vec, 'StartDateTime':starttid_vec,'OratorFirstName':navn_vec,'OratorLastName':efternavn_vec,\n",
    "                 'GroupNameShort':parti_vec,'OratorRole':rolle_vec ,'TekstGruppe':tekst_vec} # 'EndDateTime':sluttid_vec,\n",
    "df = pd.DataFrame(dictionary)\n",
    "\n",
    "print('In total, there are {} lines of text in the meetings.'.format(len(df)))\n",
    "#df.to_csv(path[0:26]+'csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110438"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(meetingID_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cleaning the data ###\n",
    "\n",
    "# The chariman (formand) does not add value to the context as he or she only moderates the debate\n",
    "# by passing on the word from person to person.\n",
    "# Also some meta data is contained regarding when the meeting ended (MødeSlut). This is also irrelevant.\n",
    "df=df[df['OratorRole']!='formand']\n",
    "df=df[df['OratorRole']!='MødeSlut']\n",
    "df['OratorRole'].dropna(axis=0,inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# Generating a column of the full name of the speakers\n",
    "df['FullName'] = df['OratorFirstName']+' '+df['OratorLastName']\n",
    "\n",
    "# Making start time into datetime64 format\n",
    "df['StartDateTime'] = df['StartDateTime'].apply(lambda x: dateutil.parser.parse(x))\n",
    "\n",
    "df['MeetingID']=df['MeetingID'].apply(lambda x: int(x))\n",
    "#df['ItemNo']=df['ItemNo'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_party_date = df.groupby(['GroupNameShort', df['StartDateTime'].dt.year, df['StartDateTime'].dt.month, df['StartDateTime'].dt.day])['TekstGruppe'].apply(lambda x : ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_agg_party_date.sort_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_name = df.groupby(['FullName'])['TekstGruppe'].apply(lambda x : ' '.join(x))\n",
    "pd.DataFrame(df_agg_name).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_date_party = df.groupby([df['StartDateTime'].dt.year, df['StartDateTime'].dt.month, df['StartDateTime'].dt.day, 'GroupNameShort'])['TekstGruppe'].apply(lambda x : ' '.join(x)).sort_index()\n",
    "pd.DataFrame(df_agg_date_party).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MeetingID']=df['MeetingID'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>TekstGruppe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StartDateTime</th>\n",
       "      <th>StartDateTime</th>\n",
       "      <th>StartDateTime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2018</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">10</th>\n",
       "      <th>2</th>\n",
       "      <td>Deres Majestæt, Deres Kongelige Højheder. I e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tid er en underlig størrelse. Jeg er f.eks. s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tak for det, formand. Nu får jeg anledning ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tak for det. Lovforslaget omfatter tre område...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Tak, hr. formand. Det her er to forslag, der ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                 TekstGruppe\n",
       "StartDateTime StartDateTime StartDateTime                                                   \n",
       "2018          10            2               Deres Majestæt, Deres Kongelige Højheder. I e...\n",
       "                            4               Tid er en underlig størrelse. Jeg er f.eks. s...\n",
       "                            9               Tak for det, formand. Nu får jeg anledning ti...\n",
       "                            10              Tak for det. Lovforslaget omfatter tre område...\n",
       "                            11              Tak, hr. formand. Det her er to forslag, der ..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg_date = df.groupby([df['StartDateTime'].dt.year, df['StartDateTime'].dt.month, df['StartDateTime'].dt.day])['TekstGruppe'].apply(lambda x : ' '.join(x)).sort_index()\n",
    "pd.DataFrame(df_agg_date).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_date_name = df.groupby([df['StartDateTime'].dt.year, df['StartDateTime'].dt.month, df['StartDateTime'].dt.day, 'FullName'])['TekstGruppe'].apply(lambda x : ' '.join(x)).sort_index()\n",
    "pd.DataFrame(df_agg_date_name).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['FullName'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_date[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = open('stopord.txt').read().splitlines() #Link: https://gist.github.com/berteltorp/0cf8a0c7afea7f25ed754f24cfc2467b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the text to a tf-idf weighted term-document matrix\n",
    "from __future__ import division\n",
    "\n",
    "# Hyperparameters\n",
    "corpus = 700000 #Der er ca. 66247 forskellige ord, efter stopord\n",
    "l1_ratio = 0\n",
    "max_iter = 50000\n",
    "no_components = 20 #number of topics\n",
    "\n",
    "# The words should appear at least 'min_df' times and at most 'max_df' pr document. Decimals indicate proportions\n",
    "min_df = 2\n",
    "max_df = 0.6\n",
    "\n",
    "data=df_agg_date_name\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=corpus, min_df=min_df, max_df=max_df, stop_words=stopwords)\n",
    "\n",
    "X = vectorizer.fit_transform(data)\n",
    " \n",
    "idx_to_word = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "\n",
    "# apply Non-negative Matrix Factorization to get topics using TF-IDF\n",
    "nmf = NMF(n_components=no_components, solver=\"mu\", l1_ratio = l1_ratio, max_iter = max_iter, random_state=1)\n",
    "\n",
    "W = nmf.fit_transform(X)\n",
    "\n",
    "H = nmf.components_\n",
    " \n",
    "# print the topics\n",
    " \n",
    "for i, topic in enumerate(H):\n",
    " \n",
    "    print(\"Topic {}: {}\".format(i + 1, \", \".join([str(x) for x in idx_to_word[topic.argsort()[-10:]]])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of words\n",
    "idx_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last topic's most defining words\n",
    "print(topic.argsort()[-10:])\n",
    "print(idx_to_word[topic.argsort()[-10:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(W)):\n",
    "#    print(W[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(H)):\n",
    "#    print(H[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are ', len(data), ' rows in this aggregation')\n",
    "print('and from these, ', W.shape[1], ' topics are computed.')\n",
    "print()\n",
    "print('There are ', len(idx_to_word),' words in the corpus.')\n",
    "print(H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_word[topic.argsort()[-10:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([data, W], axis=0, join='outer', ignore_index=False, keys=None,\n",
    "          levels=None, names=None, verify_integrity=False, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.8f' % x)\n",
    "#pd.reset_option('display.float_format')\n",
    "pd.DataFrame(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to a .csv file\n",
    "\n",
    "#with open('topics_and_weights.csv', 'w', newline='', encoding='utf-16') as csvfile:\n",
    " #   topicwriter = csv.writer(csvfile, delimiter=',',\n",
    "  #                          quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "# Create the header\n",
    "   # topicwriter.writerow(['Topic','Word','Weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the topics for tableau\n",
    " \n",
    "#for i, topic in enumerate(H):\n",
    " \n",
    " #   max_weights = topic.argsort()[-10:]\n",
    "  #  words = [str(x) for x in idx_to_word[topic.argsort()[-10:]]]\n",
    "     \n",
    "   # for count, item in enumerate(max_weights):\n",
    "        \n",
    "    #    with open('topics_and_weights.csv', 'a', newline='', encoding='utf-16') as csvfile:\n",
    "     #       topicwriter = csv.writer(csvfile, delimiter=',',\n",
    "      #                      quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "       #     topicwriter.writerow([\"Topic\"+str(i+1) ,words[count],H[i,item]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords_edit = open('stopord.txt','a')\n",
    "#stopwords_edit.write('\\nenhedslisten')\n",
    "#stopwords_edit.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
